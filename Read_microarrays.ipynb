{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef4f128",
   "metadata": {},
   "source": [
    "# Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de179b1c",
   "metadata": {},
   "source": [
    "Hola de nuevo, espero que no hayas tenido problemas con el modulo anteior de descarga :smile:, porque ahora solo se pone mas complicado :confounded:.\n",
    "\n",
    "Ahora que ya tienes los archivos suplementarios como recordaras ya tienes los datos de expresion crudos de los samples del experimento en cuestion, sin embargo, como recordaras esto aun no es suficiente para integrar los datos pues tienen distinto identificadoress que nos los hacen comparables entre si:cry:.\n",
    "\n",
    "Para solucionar este problema se tienen que hacer dos cosas: \n",
    "- En primera parsear los archivos suplementarios para poder recuperar: el valor de expresion, el probe_id, y la secuencia del probe\n",
    "- Mapear las secuencias de los probes para saber a que locus tag pertenecen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dc179",
   "metadata": {},
   "source": [
    "# Parseo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee843911",
   "metadata": {},
   "source": [
    "Como viste en el entrenamiento a travez del uso de programacion basica en python o el uso de librerias como pandas es posible parsear facilemente archivos de diferentes formatos. Sin embargo, cuando no hay modulo de apoyo, para poder parserar los datos vas a tener que entender como es el formato de tu archivo para poder extraer lo que necesitas. \n",
    "\n",
    "Ahora bien, para hacer este vas a tener que buscar los manuales de los manufacturadores que explican el formato de sus archivos, sin embargo, para propositos de este ejercicio en teoria solo tienes que buscar el de uno, el de Agilent. Esto porque no te voy a perdir que parsees los archivos de Affymetrix y te voy a ayudar con los de Nimblegen :nerd_face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19b2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jun-2025 12:30:20 DEBUG utils - Directory Results already exists. Skipping.\n",
      "20-Jun-2025 12:30:20 INFO GEOparse - File already exist: using local version.\n",
      "20-Jun-2025 12:30:20 INFO GEOparse - Parsing Results/GSM6481068.txt: \n"
     ]
    }
   ],
   "source": [
    "# Empezamos con un peque√±o ejemplo con solo un sample\n",
    "import GEOparse as geo\n",
    "import os\n",
    "import ftplib\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "gsm = geo.get_GEO(geo=\"GSM6481068\",destdir=\"Results\")\n",
    "\n",
    "# Ignora que tiene dos archivos suplementarios como es ejemplo pude revisarlos a mano xd\n",
    "ftpath = gsm.metadata[\"supplementary_file\"][0]\n",
    "\n",
    "_,_,host,*path = ftpath.split(\"/\")\n",
    "path = os.path.join(*path)\n",
    "ftp = ftplib.FTP(host)\n",
    "ftp.login()\n",
    "\n",
    "fileName = \"GSM6481068_supp.gz\"\n",
    "\n",
    "with open(pathfile:=f\"Results/{fileName}\", \"wb\") as f:\n",
    "  ftp.retrbinary(f\"RETR {path}\", f.write)\n",
    "\n",
    "ftp.quit()\n",
    "\n",
    "# Los archivos estan zipiados por lo que tienes que gunzipearlos\n",
    "\n",
    "with gzip.open(pathfile, \"rb\") as gz:\n",
    "            with open(GSM_pathunzip := pathfile.strip(\".gz\"), \"wb\") as out:\n",
    "                shutil.copyfileobj(gz, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b100ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jun-2025 12:30:32 DEBUG utils - Directory Results already exists. Skipping.\n",
      "20-Jun-2025 12:30:32 INFO GEOparse - File already exist: using local version.\n",
      "20-Jun-2025 12:30:32 INFO GEOparse - Parsing Results/GPL10416.txt: \n",
      "20-Jun-2025 12:30:32 DEBUG GEOparse - PLATFORM: GPL10416\n"
     ]
    }
   ],
   "source": [
    "# Podras pensar que solo con los samples basta, pero no en caso de nimblegen tambien se necesita el suplementario del GPL\n",
    "gpl = geo.get_GEO(geo=gsm.metadata[\"platform_id\"][0],destdir=\"Results\")\n",
    "\n",
    "ftpath = gpl.metadata[\"supplementary_file\"][0]\n",
    "\n",
    "_,_,host,*path = ftpath.split(\"/\")\n",
    "path = os.path.join(*path)\n",
    "ftp = ftplib.FTP(host)\n",
    "ftp.login()\n",
    "\n",
    "fileName = f\"{gsm.metadata['platform_id'][0]}_supp.gz\"\n",
    "\n",
    "with open(pathfile:=f\"Results/{fileName}\", \"wb\") as f:\n",
    "  ftp.retrbinary(f\"RETR {path}\", f.write)\n",
    "\n",
    "ftp.quit()\n",
    "\n",
    "with gzip.open(pathfile, \"rb\") as gz:\n",
    "            # Recuerda guardar el path de los archivos de salida para mayor comodidad\n",
    "            with open(GPL_pathunzip := pathfile.strip(\".gz\"), \"wb\") as out:\n",
    "                shutil.copyfileobj(gz, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b850017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Dado que son archivos tabulares es bastante simple el seleccionar lo que queremos\n",
    "gsm_supp = pd.read_csv(GSM_pathunzip,sep=\"\\t\",comment=\"#\")\n",
    "gpl_supp = pd.read_csv(GPL_pathunzip,sep=\"\\t\",comment=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08703685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE_ID</th>\n",
       "      <th>GENE_EXPR_OPTION</th>\n",
       "      <th>SEQ_ID</th>\n",
       "      <th>PROBE_ID</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>MATCH_INDEX</th>\n",
       "      <th>SEQ_URL</th>\n",
       "      <th>PM</th>\n",
       "      <th>MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6610-423383-425-control_532</td>\n",
       "      <td>FORWARD</td>\n",
       "      <td>NC_000913</td>\n",
       "      <td>ECOLIP1</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>820</td>\n",
       "      <td>65084075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>551.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6610-423383-425-control_532</td>\n",
       "      <td>FORWARD</td>\n",
       "      <td>NC_000913</td>\n",
       "      <td>ECOLIP25</td>\n",
       "      <td>25</td>\n",
       "      <td>542</td>\n",
       "      <td>974</td>\n",
       "      <td>65084076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      IMAGE_ID GENE_EXPR_OPTION     SEQ_ID  PROBE_ID  \\\n",
       "0  6610-423383-425-control_532          FORWARD  NC_000913   ECOLIP1   \n",
       "1  6610-423383-425-control_532          FORWARD  NC_000913  ECOLIP25   \n",
       "\n",
       "   POSITION    X    Y  MATCH_INDEX  SEQ_URL      PM   MM  \n",
       "0         1  580  820     65084075      NaN  551.33  0.0  \n",
       "1        25  542  974     65084076      NaN  475.22  0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos los archivos \n",
    "gsm_supp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26961cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROBE_DESIGN_ID</th>\n",
       "      <th>CONTAINER</th>\n",
       "      <th>DESIGN_NOTE</th>\n",
       "      <th>SELECTION_CRITERIA</th>\n",
       "      <th>SEQ_ID</th>\n",
       "      <th>PROBE_SEQUENCE</th>\n",
       "      <th>MISMATCH</th>\n",
       "      <th>MATCH_INDEX</th>\n",
       "      <th>FEATURE_ID</th>\n",
       "      <th>ROW_NUM</th>\n",
       "      <th>COL_NUM</th>\n",
       "      <th>PROBE_CLASS</th>\n",
       "      <th>PROBE_ID</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>DESIGN_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4215_0001_0001</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_000913</td>\n",
       "      <td>TGCCGGTAACGTCTGAGCGTACAATCCGGCGCGTTTTACCGCATTA...</td>\n",
       "      <td>0</td>\n",
       "      <td>65949753</td>\n",
       "      <td>65949753</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>experimental</td>\n",
       "      <td>ECOLIP1708766</td>\n",
       "      <td>1708766</td>\n",
       "      <td>4215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4215_0023_0001</td>\n",
       "      <td>FORWARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_000913</td>\n",
       "      <td>GAAGCGGCTCATTAACAGGAGTATAATGATGGATTTTTCTTTAACT...</td>\n",
       "      <td>0</td>\n",
       "      <td>65158015</td>\n",
       "      <td>65158015</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>experimental</td>\n",
       "      <td>ECOLIP1775192</td>\n",
       "      <td>1775192</td>\n",
       "      <td>4215</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PROBE_DESIGN_ID CONTAINER DESIGN_NOTE SELECTION_CRITERIA     SEQ_ID  \\\n",
       "0  4215_0001_0001   REVERSE         NaN                  0  NC_000913   \n",
       "1  4215_0023_0001   FORWARD         NaN                  0  NC_000913   \n",
       "\n",
       "                                      PROBE_SEQUENCE  MISMATCH  MATCH_INDEX  \\\n",
       "0  TGCCGGTAACGTCTGAGCGTACAATCCGGCGCGTTTTACCGCATTA...         0     65949753   \n",
       "1  GAAGCGGCTCATTAACAGGAGTATAATGATGGATTTTTCTTTAACT...         0     65158015   \n",
       "\n",
       "   FEATURE_ID  ROW_NUM  COL_NUM   PROBE_CLASS       PROBE_ID  POSITION  \\\n",
       "0    65949753        1        1  experimental  ECOLIP1708766   1708766   \n",
       "1    65158015        1       23  experimental  ECOLIP1775192   1775192   \n",
       "\n",
       "   DESIGN_ID   X  Y  \n",
       "0       4215   1  1  \n",
       "1       4215  23  1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl_supp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583f608",
   "metadata": {},
   "source": [
    "Como puedes notar cada uno tiene informacion que nos interesa, por un lado el suplementario del GSM tiene los valores crudos de la columna 'PM', y en el suplementario del GPL la secuencia asociada a ello, pero hay algo que los une, y ese es el 'PROBE_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c02df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entonces sabiendo eso podemos concatenar solo las columnas que nos interesan\n",
    "merge_sups = gsm_supp.loc[:,[\"PROBE_ID\",\"PM\"]].merge(gpl_supp.loc[:,[\"PROBE_ID\",\"PROBE_SEQUENCE\"]],on=\"PROBE_ID\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb4cf0",
   "metadata": {},
   "source": [
    "Y listo tenemos nuestros datos de interes :smile:. Aunque bueno eso solo es para un tipo de archivo de nimblegen, los .pair, para el .xys cambian los nombre de las columnas pero eso te dejare descubrirlo :+1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947c9e1",
   "metadata": {},
   "source": [
    "# Mapeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f557ef2",
   "metadata": {},
   "source": [
    "Ahora se viene lo que todos esperabamos, el mapeo de las secuencas, para ello como ya les platique previmente usamos el programa de bowtie2 para ello, aunque para eso necesitamos el genoma de referenci, aunque tu no tienes problema porque basta con que elijas el de escherichia coli k12: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/\n",
    "\n",
    "Donde solo necesitas el fna y gff\n",
    "\n",
    "Entonces ya con el genoma de referencia en tu directorio solo tienes que correr bowtie 2 de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes correrlo en la linea de bash o en python como a mi me gusta\n",
    "import os \n",
    "preffix = \"GPL\"\n",
    "fnaFilePath = \"/export/storage/users/aggonzal/Induccion/GCF_000005845.2_ASM584v2_genomic.fna.gz\"\n",
    "# Como en muchos alineadores necesitas indexar tu genoma para manejarlo de mejor manera\n",
    "# Yo no lo corro porque ya lo tengo xd\n",
    "command = f\"bowtie2-build {fnaFilePath} {preffix} > {preffix + '.out'}\"\n",
    "os.system(command=command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f31ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al alineador tienes que pasarle archivos fasta\n",
    "with open(fasta_path:=\"Fasta_attemp_2.fasta\",\"w\") as file:\n",
    "    for _,(probe,seq) in merge_sups[[\"PROBE_ID\",\"PROBE_SEQUENCE\"]].iterrows():\n",
    "        file.write(f\">{probe}\\n{seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = \"\"# El indice generado con el genoma de referencia\n",
    "out = \"\" # Nombre del output de salida\n",
    "stats = \"\" # Archivo donde se guardan las estadisticas de corrida\n",
    "command = f\"bowtie2 -f {fasta_path} -x {indice} -S {out} 2 > {stats}\"\n",
    "os.system(command=command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ade8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2#.robjects as robjects\n",
    "import tempfile\n",
    "import sys\n",
    "from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "\n",
    "bamFile = \"/export/storage/users/aggonzal/Induccion/salida_2.bam\"\n",
    "gtf = \"/export/storage/users/aggonzal/Induccion/GCF_000005845.2_ASM584v2_genomic.gtf\"\n",
    "feature = \"gene\"\n",
    "outDir = \"feature_test_2\"\n",
    "\n",
    "command = f'''\n",
    "        library(Rsubread)\n",
    "        featureCounts(\"{bamFile}\",\n",
    "        annot.ext=\"{gtf}\",\n",
    "        isGTFAnnotationFile=T,\n",
    "        nthreads=10,\n",
    "        GTF.featureType=\"{feature}\",\n",
    "        reportReads=\"CORE\",\n",
    "        reportReadsPath=\"{outDir}\", \n",
    "        verbose=F, tmpDir=\"{outDir}\")\n",
    "        '''\n",
    "#robjects.r(command)\n",
    "# Todo esto es solo para el manejo de errores con la libreria\n",
    "with tempfile.TemporaryFile(mode=\"w\") as tempFile:\n",
    "        __stdout__ = sys.stdout\n",
    "        sys.stdout = tempFile\n",
    "        try:\n",
    "                rpy2.robjects.r(command)\n",
    "        except RRuntimeError:\n",
    "                print(\"Valio sorbete\")\n",
    "        \n",
    "        sys.stdout = __stdout__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec458cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya solo tienes que renotar los probes para que los valores esten asociados a sus locus tag correspondientes\n",
    "import pandas as pd\n",
    "features = pd.read_csv(\"feature_test_2/salida_2.bam.featureCounts\",sep=\"\\t\",header=None)\n",
    "features.columns = [\"PROBE_ID\",\"ASSIGN\",\"VALUE\",\"GENE\"]\n",
    "probe_feature = merge_sups.merge(features.loc[:,[\"PROBE_ID\",\"GENE\"]],on=\"PROBE_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la matriz solo necesitas el valor y el nombre del gen\n",
    "matriz = probe_feature.dropna()[[\"GENE\",\"PM\"]].drop_duplicates()\n",
    "matriz.set_index(\"GENE\",inplace=True)\n",
    "# En este caso sabemos que todos nuestros valor pertenecen a un solo sample\n",
    "matriz.rename(columns={\"PM\":\"GSM6481068\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ff0419ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM6481068</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b0001</th>\n",
       "      <td>312.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0001</th>\n",
       "      <td>473.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0001</th>\n",
       "      <td>739.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0001</th>\n",
       "      <td>454.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0001</th>\n",
       "      <td>162.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GSM6481068\n",
       "GENE             \n",
       "b0001      312.33\n",
       "b0001      473.33\n",
       "b0001      739.33\n",
       "b0001      454.78\n",
       "b0001      162.22"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y listo tenemos una columna de la matriz de expresion\n",
    "matriz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d2ccd",
   "metadata": {},
   "source": [
    "# Actividad :horse: :fire: :fire:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51b2dd",
   "metadata": {},
   "source": [
    "Espero que los codigos que te di se pudieran entender :smiley_cat:, pero ahora es tiempo de ponerlo en practica como ya sabes, pero tranquilo si alguna cosa no funciona lo podemos revisar.\n",
    "\n",
    "Para este modulo solo te voy a pedir lo siguiente:\n",
    "Para aquellos gsms a los que les descargaste suplementarios, exclusivamente aquellos con manufacturadores de Nimblegen o Agilent; deberas realizar un parseo de los archivos suplementarios para la extraccion de minimo el valor crudo, la secuencia y el probe_id. \n",
    "\n",
    "Para posteriormente mapear las secuencias y recuperar el locus tag asociado a cada valor, ojo si algunas de las secuencias no mapean y se pierden esta bien. \n",
    "\n",
    "Finalmente una vez recuperados los locus tag construye una matriz de expresion donde las filas sean los locus tag y las columnas los gsms, para todos los gsms que pudiste recuperar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7ead2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muDAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
